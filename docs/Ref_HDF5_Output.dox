\<!-------------------------------------------->


\page hdf5_output Dakota HDF5 Output

Beginning with release 6.9, %Dakota can write many method 
results such as the correlation matrices computed by 
\ref method-sampling studies and the best parameters 
discovered by optimization methods to disk in **HDF5**. Many 
users may find this newly supported format more convenient 
than scraping or copying and pasting from Dakota's console
output.

To enable HDF5 output, the \ref environment-results_output 
keyword with the \ref environment-results_output-hdf5 option 
must be added to the Dakota input file. In additon, Dakota must 
have been built with HDF5 support. HDF5 support is considered a 
somewhat experimental feature in this release, and therefore HDF5
is not enabled in binaries provided on the Download page of the Dakota 
website; building from source is necessary. See the instructions on 
the Dakota website.

\section hdf5_output-description HDF5 Concepts

HDF5 is a format that is widely used in scientific software for 
efficiently storing and organizing data. The HDF5 standard and 
libraries are maintained by the [HDF Group](https://hdfgroup.org).

In HDF5, data are stored in multidimensional arrays called *datasets*. 
Datasets are organized hierarchically in *groups*, which also can 
contain other groups. Datasets and groups are conceptually similar 
to files and directories in a filesystem. In fact, every HDF5 file 
contains at least one group, the root group, denoted "/", and
groups and datasets are referred to using slash-delimited absolute or
relative paths, which are more accurately called *link names*.

\image html hdf5_layout.png "Example HDF5 Layout"



HDF5 has as one goal that data be "self-documenting" through the 
use of metadata. %Dakota output files include two kinds of
metadata.
- **Dimension Scales**. Each dimension of a dataset may have zero or more
  scales, which are themselves datasets. Scales are often used to 
  provide, for example, labels analogous to column headings 
  in a table (see the dimension scales that %Dakota applies to 
  \ref hdf5_results-sampling_moments "moments") or numerical values 
  of an indepenent variable (user-specified probability levels in 
  \ref hdf5_results-level_mappings "level mappings").
- **Attributes**. key:value pairs that annotate a group or dataset. A key
  is always a character string, such as \c dakota_version, and (in Dakota 
  output) the value can be a string-, integer-, or real-valued scalar. 
  %Dakota stores the number of samples that were requested 
  in a \c sampling study in the attribute 'samples'.

\section hdf5_output-accessing Accessing Results

Many popular programming languages have support, either natively or from
a third-party library, for reading and writing HDF5 files. The HDF Group
itself supports C/C++ and Java libraries. The Dakota Project suggests 
the \c h5py module for Python. Examples that demonstrate using \c h5py
to access and use Dakota HDF5 output may be found in the Dakota installation
at \c share/dakota/examples/hdf5.

\section hdf5_results Organization of Results

Currently, complete or nearly complete coverage of results from sampling, 
optimization and calibration methods, parameter studies, and stochastic 
expansions exists. Coverage will continue to expand in future releases 
to include not only the results of all methods, but other potentially useful
information such as interface evaluations and model tranformations.

Methods in Dakota have a character string ID and are executed by Dakota one or
more times. (Methods are executed more than once in studies that
include a \ref model-nested "nested model", for example.) The ID may be provided by 
the user in the input file using the \ref method-id_method keyword, or it may be
automatically generated by Dakota. Dakota uses the label \c NO_ID for methods
that are specified in the input file without an \c id_method, and \c NOSPEC_ID_\<N\> 
for methods that it generates for its own internal use. The \<N\> in the latter 
case is an incrementing integer that begins at 1.

The results for the \<N\>th execution of a method that has the label \c \<method_id\> 
are stored in the group

    /methods/<method_id>/execution:<N>/

The \c /methods group is always present in Dakota HDF5 files, provided at
least one method added results to the output. (In a future Dakota release, the top
level groups \c /interfaces and \c /models will be added.) The group \c execution:1
also is always present, even if there is only a single execution.

The groups and datasets for each type of result that Dakota is currently capable
of storing are described in the following sections. Every dataset is documented
in its own table. These tables include: 

- A brief *description* of the dataset.
- The *location* of the dataset relative to `/methods/<method_id>/execution:<N>`.
  This path may include both literal text that is always present and replacement text.
  Replacement text is \<*enclosed in angle brackets and italicized*\>. Two examples of 
  replacement text are \<*response descriptor*\> and  \<*variable descriptor*\>, which 
  indicate that the name of a Dakota response or variable makes up a portion of the path.
- Clarifying *notes*, where appropriate.
- The *type* (String, Integer, or Real) of the information in the dataset.
- The *shape* of the dataset; that is, the number of dimensions and the size of each 
  dimension.
- A description of the dataset's *scales*, which includes
  + The *dimension* of the dataset that the scale belongs to.
  + The *type* (String, Integer, or Real) of the information in the scale.
  + The *label* or name of the scale.
  + The *contents* of the scale. Contents that appear in plaintext are literal and will
    always be present in a scale. Italicized text describes content that varies.
  + *notes* that provide further clarification about the scale.
- A description of the dataset's *attributes*, which are key:value pairs that provide
  helpful context for the dataset.

The **Expected Output** section of each \ref method's keyword documentation 
indicates the kinds of output, if any, that method currently can write to HDF5. These 
are typically in the form of bulleted lists with clariying notes that refer 
back to the sections that follow.

\subsection hdf5_results-metadata Study Metadata

Several pieces of information about the Dakota study are stored as
attributes of the top-level HDF5 root group ("/"). These include:

\htmlinclude study_attributes_table.html

\subsection hdf5_results-variables A Note about Variables Storage

Variables in most Dakota output (e.g. tabular data files) and input (e.g. imported
data to construct surrogates) are listed in "input spec" order. (The \ref variables 
keyword section is arranged by input spec order.) In this ordering, they are sorted
first by function:
1. Design
2. Aleatory
3. Epistemic
4. State

And within each of these categories, they are sorted by domain:
1. Continuous
2. Discrete integer (sets and ranges)
3. Discrete string
4. Discrete real

A shortcoming of HDF5 is that datasets are homogeneous; for example, string- and 
real-valued data cannot readily be stored in the same dataset. As a result,
Dakota has chosen to flip "input spec" order for HDF5 and sort first by domain, then 
by function when storing variable information. When applicable, there may
be as many as four datasets to store variable information: one to store continuous 
variables, another to store discrete integer variables, and so on. Within each of these, 
variables will be ordered by function.

\subsection hdf5_results-sampling_moments Sampling Moments

\ref method-sampling produces moments (e.g. mean, standard deviation or
variance) of all responses, as well as 95% lower and upper confidence
intervals for the 1st and 2nd moments. These are stored as described below.
When \ref method-sampling is used in incremental mode by specifying
\ref method-sampling-refinement_samples, all results, including the \c moments group,
are placed within groups named \c increment:\<N\>, where \<N\> indicates
the increment number beginning with 1.

\htmlinclude sampling_moments.html
<br>
\htmlinclude moment_confidence_intervals.html

\subsection hdf5_results-correlations Correlations

A few different methods produce information about the correlations between
pairs of variables and responses (collectively: factors). The four tables
in this section describe how correlation information is stored. One important
note is that HDF5 has no special, native type for symmetric matrices, and so
the simple correlations and simple rank correlations are stored in dense 2D
datasets.

\htmlinclude simple_corr.html
<br>
\htmlinclude simple_rank_corr.html
<br>
\htmlinclude partial_corr.html
<br>
\htmlinclude partial_rank_corr.html

\subsection hdf5_results-pdf Probability Density

Some aleatory UQ methods estimate the probability density of resposnes.

\htmlinclude pdf.html

\subsection hdf5_results-level_mappings Level Mappings

Aleatory UQ methods can calculate level mappings (from user-specified probability,
reliability, or generalized reliability to response, or vice versa).

\htmlinclude prob_levels.html
<br>
\htmlinclude rel_levels.html
<br>
\htmlinclude gen_rel_levels.html
<br>
\htmlinclude response_levels.html
 
\subsection hdf5_results-vbd Variance-Based Decomposition (Sobol' Indices)
Dakota's \ref method-sampling method can produce main and total effects; stochastic
expansions (\ref method-polynomial_chaos, \ref method-stoch_collocation) additionally
can produce interaction effects.
\htmlinclude vbd_main.html
<br>
\htmlinclude vbd_total.html
Each order (pair, 3-way, 4-way, etc) of interaction is stored in a separate dataset. The
scales are unusual in that they are two-dimensional to contain the labels of the variables
that participate in each interaction.
\htmlinclude vbd_interactions.html


\subsection hdf5_results-se_moments Integration and Expansion Moments
Stochastic expansion methods can obtain moments two ways.
\htmlinclude int_moments.html
<br>
\htmlinclude exp_moments.html

\subsection hdf5_results-extreme_responses Extreme Responses
\ref method-sampling with epistemic variables produces extreme values (minimum and maximum)
for each response.
\htmlinclude extreme_responses.html

\subsection hdf5_results-pstudies Parameter Studies

All parameter studies (\ref method-vector_parameter_study, \ref method-list_parameter_study,
\ref method-multidim_parameter_study, \ref method-centered_parameter_study) record tables of
evaluations (parameter-response pairs), similar to Dakota's tabular output file. Centered 
parameter studies additionally store evaluations in an order that is more natural to intepret, 
which is described below.

In the tabular-like listing, variables are stored according to the scheme described in a 
\ref hdf5_results-variables "previous section".

\htmlinclude parameter_sets.html

Centered paramter studies also store "slices" of the tabular data that make evaluating the
effects of each variable on each response more convenient. The steps for each individual 
variable, including the initial or center point, and corresponding responses are stored 
in separate groups.

\htmlinclude cps_var_slices_steps.html
<br>
\htmlinclude cps_var_slices_resps.html

\subsection hdf5_results-best_params Best Parameters

Dakota's optimization and calibration methods report the parameters at the best point
(or points, for multiple \ref method-final_solutions "final solutions") discovered. These
are stored using the scheme decribed in the \ref hdf5_results-variables "variables" section. When 
more than one solution is reported, the best parameters are nested in groups named \c set:\<N\>, 
where \<N\> is a integer numbering the set and beginning with 1.

State (and other inactive variables) are reported when using
\ref responses-objective_functions "objective functions" and for some 
\ref responses-calibration_terms "calibration" studies. However, when using configuration 
variables in a calibration, state variables are suppressed.

\htmlinclude best_parameters.html

\subsection hdf5_results-best_obj_fncs Best Objective Functions

Dakota's optimization methods report the objective functions at the best point (or points,
for multiple \ref method-final_solutions "final solutions") discovered. When 
more than one solution is reported, the best objective functions are nested in groups named \c set:\<N\>, 
where \<N\> is a integer numbering the set and beginning with 1.

\htmlinclude best_objective_functions.html

\subsection hdf5_results-best_constraints Best Nonlinear Constraints

Dakota's optimization and calibration methods report the nonlinear constraints at the best 
point (or points, for multiple \ref method-final_solutions "final solutions") discovered. When 
more than one solution is reported, the best constraints are nested in groups named \c set:\<N\>, 
where `N` is a integer numbering the set and beginning with 1.


\htmlinclude best_constraints.html

\subsection hdf5_results-calibration Calibration

When using \ref responses-calibration_terms "calibration terms" with an optimization method, or 
when using a nonlinear least squares method such as \ref method-nl2sol, Dakota reports residuals
and residual norms for the best point (or points, for multiple 
\ref method-final_solutions "final solutions") discovered.

\htmlinclude best_residuals.html
<br>
\htmlinclude best_residual_norm.html

\subsection hdf5_results-calibration-no_config Best Model Responses (without configuration variables)

When performing calibration with experimental data (but no configruation variables),
Dakota records, in addition to the best residuals, the best original model resposnes.

\htmlinclude best_model_responses.html

\subsection hdf5_results-calibration-config Best Model Responses (with configuration variables)

When performing calibration with experimental data that includes configuration variables, Dakota
reports the best model responses for each experiment. These results include the configuration 
variables, stored in the scheme described in the \ref hdf5_results-variables "variables" section,
and the model responses.

\htmlinclude best_config_vars.html
<br>
\htmlinclude best_model_resps_config_vars.html

